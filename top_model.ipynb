{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('train_data_reduced/x_train_150000_bottleneck.npy')\n",
    "x_cv=np.load('train_data_reduced/x_cv_25000_bottleneck.npy')\n",
    "\n",
    "y_train=np.load('train_data_reduced/y_train_150000.npy')\n",
    "y_cv=np.load('train_data_reduced/y_cv_25000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_lr(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "\t    K.set_value(self.model.optimizer.lr, 0.001)\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        lr_present=K.get_value(self.model.optimizer.lr)\n",
    "        #print(epoch)\n",
    "        if (epoch%10==0) and epoch:\n",
    "        \t\n",
    "            K.set_value(self.model.optimizer.lr, lr_present/((epoch)**0.5))\n",
    "            print(K.get_value(self.model.optimizer.lr))\n",
    "            print(lr_present/((epoch)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 131,201\n",
      "Trainable params: 131,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "\t    Custom_lr()\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150000 samples, validate on 25000 samples\n",
      "Epoch 1/35\n",
      "150000/150000 [==============================] - 17s 113us/step - loss: 0.6290 - acc: 0.6680 - val_loss: 0.5196 - val_acc: 0.7350\n",
      "Epoch 2/35\n",
      "150000/150000 [==============================] - 16s 110us/step - loss: 0.5444 - acc: 0.7069 - val_loss: 0.4953 - val_acc: 0.7519\n",
      "Epoch 3/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.5162 - acc: 0.7274 - val_loss: 0.4614 - val_acc: 0.7717\n",
      "Epoch 4/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.4982 - acc: 0.7413 - val_loss: 0.4572 - val_acc: 0.7760\n",
      "Epoch 5/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.4816 - acc: 0.7488 - val_loss: 0.4456 - val_acc: 0.7815\n",
      "Epoch 6/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.4698 - acc: 0.7566 - val_loss: 0.4258 - val_acc: 0.7948\n",
      "Epoch 7/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.4563 - acc: 0.7646 - val_loss: 0.4210 - val_acc: 0.7988\n",
      "Epoch 8/35\n",
      "150000/150000 [==============================] - 16s 110us/step - loss: 0.4476 - acc: 0.7695 - val_loss: 0.4185 - val_acc: 0.8060\n",
      "Epoch 9/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.4367 - acc: 0.7753 - val_loss: 0.4081 - val_acc: 0.8108\n",
      "Epoch 10/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.4301 - acc: 0.7785 - val_loss: 0.4072 - val_acc: 0.8106\n",
      "Epoch 11/35\n",
      "0.0003162278\n",
      "0.00031622778103685084\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3979 - acc: 0.7952 - val_loss: 0.3865 - val_acc: 0.8226\n",
      "Epoch 12/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3892 - acc: 0.7991 - val_loss: 0.3846 - val_acc: 0.8262\n",
      "Epoch 13/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3823 - acc: 0.8020 - val_loss: 0.3827 - val_acc: 0.8268\n",
      "Epoch 14/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3772 - acc: 0.8051 - val_loss: 0.3817 - val_acc: 0.8309\n",
      "Epoch 15/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3724 - acc: 0.8075 - val_loss: 0.3824 - val_acc: 0.8320\n",
      "Epoch 16/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3674 - acc: 0.8095 - val_loss: 0.3814 - val_acc: 0.8325\n",
      "Epoch 17/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3636 - acc: 0.8110 - val_loss: 0.3799 - val_acc: 0.8344\n",
      "Epoch 18/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3606 - acc: 0.8124 - val_loss: 0.3775 - val_acc: 0.8360\n",
      "Epoch 19/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3592 - acc: 0.8127 - val_loss: 0.3794 - val_acc: 0.8362\n",
      "Epoch 20/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3524 - acc: 0.8171 - val_loss: 0.3775 - val_acc: 0.8367\n",
      "Epoch 21/35\n",
      "7.071068e-05\n",
      "7.071068264135355e-05\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3432 - acc: 0.8222 - val_loss: 0.3766 - val_acc: 0.8386\n",
      "Epoch 22/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3392 - acc: 0.8229 - val_loss: 0.3768 - val_acc: 0.8402\n",
      "Epoch 23/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3361 - acc: 0.8250 - val_loss: 0.3788 - val_acc: 0.8396\n",
      "Epoch 24/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.3343 - acc: 0.8239 - val_loss: 0.3783 - val_acc: 0.8422\n",
      "Epoch 25/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3342 - acc: 0.8249 - val_loss: 0.3790 - val_acc: 0.8420\n",
      "Epoch 26/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3313 - acc: 0.8254 - val_loss: 0.3788 - val_acc: 0.8424\n",
      "Epoch 27/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3299 - acc: 0.8270 - val_loss: 0.3797 - val_acc: 0.8429\n",
      "Epoch 28/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3300 - acc: 0.8270 - val_loss: 0.3807 - val_acc: 0.8426\n",
      "Epoch 29/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3292 - acc: 0.8284 - val_loss: 0.3805 - val_acc: 0.8426\n",
      "Epoch 30/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3265 - acc: 0.8275 - val_loss: 0.3830 - val_acc: 0.8422\n",
      "Epoch 31/35\n",
      "1.2909945e-05\n",
      "1.2909945018820682e-05\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3241 - acc: 0.8315 - val_loss: 0.3820 - val_acc: 0.8425\n",
      "Epoch 32/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3242 - acc: 0.8308 - val_loss: 0.3824 - val_acc: 0.8434\n",
      "Epoch 33/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3215 - acc: 0.8318 - val_loss: 0.3833 - val_acc: 0.8428\n",
      "Epoch 34/35\n",
      "150000/150000 [==============================] - 16s 108us/step - loss: 0.3227 - acc: 0.8302 - val_loss: 0.3837 - val_acc: 0.8430\n",
      "Epoch 35/35\n",
      "150000/150000 [==============================] - 16s 109us/step - loss: 0.3230 - acc: 0.8318 - val_loss: 0.3833 - val_acc: 0.8426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bbbb623630>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.fit(x_train, y_train,\n",
    "          epochs=35,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_cv, y_cv), callbacks=callbacks,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save('top_model_64_adam_custom_lr.h5') # best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 66,657\n",
      "Trainable params: 66,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "top_model.add(Dense(32, activation='relu'))\n",
    "top_model.add(Dropout(0.3))\n",
    "top_model.add(Dense(32))\n",
    "top_model.add(LeakyReLU())\n",
    "top_model.add(Dropout(0.3))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150000 samples, validate on 25000 samples\n",
      "Epoch 1/35\n",
      "150000/150000 [==============================] - 20s 130us/step - loss: 0.5470 - acc: 0.7017 - val_loss: 0.5080 - val_acc: 0.7396\n",
      "Epoch 2/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.5177 - acc: 0.7231 - val_loss: 0.4836 - val_acc: 0.7608\n",
      "Epoch 3/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.4939 - acc: 0.7398 - val_loss: 0.4641 - val_acc: 0.7672\n",
      "Epoch 4/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.4783 - acc: 0.7492 - val_loss: 0.4527 - val_acc: 0.7714\n",
      "Epoch 5/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.4614 - acc: 0.7572 - val_loss: 0.4437 - val_acc: 0.7851\n",
      "Epoch 6/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.4525 - acc: 0.7637 - val_loss: 0.4389 - val_acc: 0.7855\n",
      "Epoch 7/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.4408 - acc: 0.7702 - val_loss: 0.4372 - val_acc: 0.7921\n",
      "Epoch 8/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.4328 - acc: 0.7739 - val_loss: 0.4289 - val_acc: 0.7945\n",
      "Epoch 9/35\n",
      "150000/150000 [==============================] - 20s 133us/step - loss: 0.4247 - acc: 0.7791 - val_loss: 0.4301 - val_acc: 0.7902\n",
      "Epoch 10/35\n",
      "150000/150000 [==============================] - 19s 129us/step - loss: 0.4194 - acc: 0.7824 - val_loss: 0.4246 - val_acc: 0.7981\n",
      "Epoch 11/35\n",
      "150000/150000 [==============================] - 20s 130us/step - loss: 0.4123 - acc: 0.7861 - val_loss: 0.4275 - val_acc: 0.8013\n",
      "Epoch 12/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.4076 - acc: 0.7899 - val_loss: 0.4171 - val_acc: 0.8031\n",
      "Epoch 13/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.4024 - acc: 0.7935 - val_loss: 0.4172 - val_acc: 0.8034\n",
      "Epoch 14/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3976 - acc: 0.7958 - val_loss: 0.4206 - val_acc: 0.8065\n",
      "Epoch 15/35\n",
      "150000/150000 [==============================] - 20s 131us/step - loss: 0.3926 - acc: 0.7995 - val_loss: 0.4177 - val_acc: 0.8071\n",
      "Epoch 16/35\n",
      "150000/150000 [==============================] - 19s 129us/step - loss: 0.3863 - acc: 0.8025 - val_loss: 0.4103 - val_acc: 0.8112\n",
      "Epoch 17/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3837 - acc: 0.8046 - val_loss: 0.4167 - val_acc: 0.8067\n",
      "Epoch 18/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3784 - acc: 0.8070 - val_loss: 0.4116 - val_acc: 0.8106\n",
      "Epoch 19/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3749 - acc: 0.8096 - val_loss: 0.4131 - val_acc: 0.8151\n",
      "Epoch 20/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3727 - acc: 0.8127 - val_loss: 0.4127 - val_acc: 0.8183\n",
      "Epoch 21/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3684 - acc: 0.8147 - val_loss: 0.4114 - val_acc: 0.8184\n",
      "Epoch 22/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3672 - acc: 0.8149 - val_loss: 0.4319 - val_acc: 0.8191\n",
      "Epoch 23/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3616 - acc: 0.8175 - val_loss: 0.4106 - val_acc: 0.8159\n",
      "Epoch 24/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3599 - acc: 0.8188 - val_loss: 0.4195 - val_acc: 0.8165\n",
      "Epoch 25/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3579 - acc: 0.8201 - val_loss: 0.4300 - val_acc: 0.8208\n",
      "Epoch 26/35\n",
      "150000/150000 [==============================] - 19s 126us/step - loss: 0.3550 - acc: 0.8204 - val_loss: 0.4131 - val_acc: 0.8147\n",
      "Epoch 27/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3522 - acc: 0.8226 - val_loss: 0.4062 - val_acc: 0.8135\n",
      "Epoch 28/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3500 - acc: 0.8224 - val_loss: 0.4155 - val_acc: 0.8220\n",
      "Epoch 29/35\n",
      "150000/150000 [==============================] - 19s 126us/step - loss: 0.3491 - acc: 0.8252 - val_loss: 0.4134 - val_acc: 0.8220\n",
      "Epoch 30/35\n",
      "150000/150000 [==============================] - 19s 129us/step - loss: 0.3455 - acc: 0.8268 - val_loss: 0.4088 - val_acc: 0.8250\n",
      "Epoch 31/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3449 - acc: 0.8281 - val_loss: 0.4222 - val_acc: 0.8232\n",
      "Epoch 32/35\n",
      "150000/150000 [==============================] - 19s 128us/step - loss: 0.3438 - acc: 0.8281 - val_loss: 0.4212 - val_acc: 0.8215\n",
      "Epoch 33/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3418 - acc: 0.8282 - val_loss: 0.4273 - val_acc: 0.8270\n",
      "Epoch 34/35\n",
      "150000/150000 [==============================] - 19s 127us/step - loss: 0.3389 - acc: 0.8296 - val_loss: 0.4264 - val_acc: 0.8238\n",
      "Epoch 35/35\n",
      "150000/150000 [==============================] - 19s 126us/step - loss: 0.3382 - acc: 0.8324 - val_loss: 0.4049 - val_acc: 0.8232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bbc8a12748>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.fit(x_train, y_train,\n",
    "          epochs=35,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save('top_model_2_layer_leaky_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "top_model.add(Dense(32, activation='relu'))\n",
    "top_model.add(Dropout(0.35))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150000 samples, validate on 25000 samples\n",
      "Epoch 1/35\n",
      "150000/150000 [==============================] - 18s 119us/step - loss: 0.5983 - acc: 0.6776 - val_loss: 0.5123 - val_acc: 0.7374\n",
      "Epoch 2/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.5286 - acc: 0.7216 - val_loss: 0.4885 - val_acc: 0.7550\n",
      "Epoch 3/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.5031 - acc: 0.7390 - val_loss: 0.4658 - val_acc: 0.7708\n",
      "Epoch 4/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4836 - acc: 0.7493 - val_loss: 0.4478 - val_acc: 0.7815\n",
      "Epoch 5/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4672 - acc: 0.7582 - val_loss: 0.4413 - val_acc: 0.7886\n",
      "Epoch 6/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4545 - acc: 0.7659 - val_loss: 0.4355 - val_acc: 0.7945\n",
      "Epoch 7/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4434 - acc: 0.7725 - val_loss: 0.4267 - val_acc: 0.7999\n",
      "Epoch 8/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4339 - acc: 0.7774 - val_loss: 0.4212 - val_acc: 0.8038\n",
      "Epoch 9/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.4269 - acc: 0.7801 - val_loss: 0.4175 - val_acc: 0.8020\n",
      "Epoch 10/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4196 - acc: 0.7861 - val_loss: 0.4126 - val_acc: 0.8097\n",
      "Epoch 11/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4106 - acc: 0.7897 - val_loss: 0.4171 - val_acc: 0.8105\n",
      "Epoch 12/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4071 - acc: 0.7927 - val_loss: 0.4136 - val_acc: 0.8129\n",
      "Epoch 13/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.4012 - acc: 0.7944 - val_loss: 0.4125 - val_acc: 0.8140\n",
      "Epoch 14/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3968 - acc: 0.7987 - val_loss: 0.4181 - val_acc: 0.8098\n",
      "Epoch 15/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3922 - acc: 0.7998 - val_loss: 0.4093 - val_acc: 0.8148\n",
      "Epoch 16/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3866 - acc: 0.8027 - val_loss: 0.4098 - val_acc: 0.8178\n",
      "Epoch 17/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3837 - acc: 0.8045 - val_loss: 0.4075 - val_acc: 0.8165\n",
      "Epoch 18/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3778 - acc: 0.8078 - val_loss: 0.4085 - val_acc: 0.8194\n",
      "Epoch 19/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3763 - acc: 0.8082 - val_loss: 0.4134 - val_acc: 0.8218\n",
      "Epoch 20/35\n",
      "150000/150000 [==============================] - 17s 113us/step - loss: 0.3737 - acc: 0.8097 - val_loss: 0.4175 - val_acc: 0.8178\n",
      "Epoch 21/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3687 - acc: 0.8127 - val_loss: 0.4127 - val_acc: 0.8214\n",
      "Epoch 22/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3658 - acc: 0.8147 - val_loss: 0.4124 - val_acc: 0.8207\n",
      "Epoch 23/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3652 - acc: 0.8144 - val_loss: 0.4035 - val_acc: 0.8224\n",
      "Epoch 24/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3605 - acc: 0.8170 - val_loss: 0.4119 - val_acc: 0.8186\n",
      "Epoch 25/35\n",
      "150000/150000 [==============================] - 17s 114us/step - loss: 0.3591 - acc: 0.8174 - val_loss: 0.4175 - val_acc: 0.8226\n",
      "Epoch 26/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3556 - acc: 0.8184 - val_loss: 0.4178 - val_acc: 0.8246\n",
      "Epoch 27/35\n",
      "150000/150000 [==============================] - 17s 113us/step - loss: 0.3554 - acc: 0.8193 - val_loss: 0.4129 - val_acc: 0.8230\n",
      "Epoch 28/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3521 - acc: 0.8187 - val_loss: 0.4181 - val_acc: 0.8240\n",
      "Epoch 29/35\n",
      "150000/150000 [==============================] - 17s 113us/step - loss: 0.3512 - acc: 0.8219 - val_loss: 0.4115 - val_acc: 0.8276\n",
      "Epoch 30/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3497 - acc: 0.8221 - val_loss: 0.4193 - val_acc: 0.8265\n",
      "Epoch 31/35\n",
      "150000/150000 [==============================] - 17s 113us/step - loss: 0.3483 - acc: 0.8225 - val_loss: 0.4266 - val_acc: 0.8259\n",
      "Epoch 32/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3455 - acc: 0.8235 - val_loss: 0.4261 - val_acc: 0.8244\n",
      "Epoch 33/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3446 - acc: 0.8259 - val_loss: 0.4210 - val_acc: 0.8277\n",
      "Epoch 34/35\n",
      "150000/150000 [==============================] - 17s 111us/step - loss: 0.3413 - acc: 0.8268 - val_loss: 0.4271 - val_acc: 0.8244\n",
      "Epoch 35/35\n",
      "150000/150000 [==============================] - 17s 112us/step - loss: 0.3415 - acc: 0.8265 - val_loss: 0.4232 - val_acc: 0.8227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bbcc67b978>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.fit(x_train, y_train,\n",
    "          epochs=35,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_cv, y_cv),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save('top_model_32_adam.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train best top model architecture on larger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('train_data/x_train_bottleneck.npy')\n",
    "x_cv=np.load('train_data/x_cv_bottleneck.npy')\n",
    "\n",
    "y_train=np.load('train_data/y_train.npy')\n",
    "y_cv=np.load('train_data/y_cv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 131,201\n",
      "Trainable params: 131,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "\t    Custom_lr()\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 245509 samples, validate on 105219 samples\n",
      "Epoch 1/35\n",
      "245509/245509 [==============================] - 29s 120us/step - loss: 0.6017 - acc: 0.6863 - val_loss: 0.5006 - val_acc: 0.7479\n",
      "Epoch 2/35\n",
      "245509/245509 [==============================] - 29s 120us/step - loss: 0.5225 - acc: 0.7241 - val_loss: 0.4587 - val_acc: 0.7744\n",
      "Epoch 3/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.4957 - acc: 0.7401 - val_loss: 0.4426 - val_acc: 0.7843\n",
      "Epoch 4/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.4786 - acc: 0.7508 - val_loss: 0.4298 - val_acc: 0.7941\n",
      "Epoch 5/35\n",
      "245509/245509 [==============================] - 29s 118us/step - loss: 0.4646 - acc: 0.7583 - val_loss: 0.4165 - val_acc: 0.8000\n",
      "Epoch 6/35\n",
      "245509/245509 [==============================] - 29s 118us/step - loss: 0.4545 - acc: 0.7632 - val_loss: 0.4088 - val_acc: 0.8051\n",
      "Epoch 7/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.4441 - acc: 0.7689 - val_loss: 0.3916 - val_acc: 0.8151\n",
      "Epoch 8/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.4356 - acc: 0.7748 - val_loss: 0.3874 - val_acc: 0.8211\n",
      "Epoch 9/35\n",
      "245509/245509 [==============================] - 29s 118us/step - loss: 0.4275 - acc: 0.7786 - val_loss: 0.3798 - val_acc: 0.8236\n",
      "Epoch 10/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.4220 - acc: 0.7819 - val_loss: 0.3851 - val_acc: 0.8225\n",
      "Epoch 11/35\n",
      "0.0003162278\n",
      "0.00031622778103685084\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3929 - acc: 0.7946 - val_loss: 0.3598 - val_acc: 0.8357\n",
      "Epoch 12/35\n",
      "245509/245509 [==============================] - 28s 116us/step - loss: 0.3840 - acc: 0.8000 - val_loss: 0.3560 - val_acc: 0.8385\n",
      "Epoch 13/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3772 - acc: 0.8027 - val_loss: 0.3553 - val_acc: 0.8396\n",
      "Epoch 14/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3720 - acc: 0.8060 - val_loss: 0.3496 - val_acc: 0.8417\n",
      "Epoch 15/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3685 - acc: 0.8063 - val_loss: 0.3491 - val_acc: 0.8416\n",
      "Epoch 16/35\n",
      "245509/245509 [==============================] - 29s 118us/step - loss: 0.3654 - acc: 0.8092 - val_loss: 0.3475 - val_acc: 0.8442\n",
      "Epoch 17/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.3630 - acc: 0.8108 - val_loss: 0.3471 - val_acc: 0.8445\n",
      "Epoch 18/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.3602 - acc: 0.8117 - val_loss: 0.3464 - val_acc: 0.8455\n",
      "Epoch 19/35\n",
      "245509/245509 [==============================] - 29s 118us/step - loss: 0.3581 - acc: 0.8142 - val_loss: 0.3459 - val_acc: 0.8462\n",
      "Epoch 20/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3546 - acc: 0.8155 - val_loss: 0.3437 - val_acc: 0.8475\n",
      "Epoch 21/35\n",
      "7.071068e-05\n",
      "7.071068264135355e-05\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3432 - acc: 0.8207 - val_loss: 0.3417 - val_acc: 0.8498\n",
      "Epoch 22/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3415 - acc: 0.8211 - val_loss: 0.3405 - val_acc: 0.8501\n",
      "Epoch 23/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.3404 - acc: 0.8227 - val_loss: 0.3405 - val_acc: 0.8508\n",
      "Epoch 24/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.3378 - acc: 0.8241 - val_loss: 0.3404 - val_acc: 0.8507\n",
      "Epoch 25/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3371 - acc: 0.8228 - val_loss: 0.3398 - val_acc: 0.8513\n",
      "Epoch 26/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3358 - acc: 0.8243 - val_loss: 0.3399 - val_acc: 0.8517\n",
      "Epoch 27/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3345 - acc: 0.8247 - val_loss: 0.3406 - val_acc: 0.8519\n",
      "Epoch 28/35\n",
      "245509/245509 [==============================] - 29s 117us/step - loss: 0.3344 - acc: 0.8256 - val_loss: 0.3400 - val_acc: 0.8510\n",
      "Epoch 29/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3331 - acc: 0.8261 - val_loss: 0.3394 - val_acc: 0.8527\n",
      "Epoch 30/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3328 - acc: 0.8265 - val_loss: 0.3397 - val_acc: 0.8523\n",
      "Epoch 31/35\n",
      "1.2909945e-05\n",
      "1.2909945018820682e-05\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3300 - acc: 0.8275 - val_loss: 0.3393 - val_acc: 0.8522\n",
      "Epoch 32/35\n",
      "245509/245509 [==============================] - 28s 116us/step - loss: 0.3289 - acc: 0.8281 - val_loss: 0.3395 - val_acc: 0.8527\n",
      "Epoch 33/35\n",
      "245509/245509 [==============================] - 28s 116us/step - loss: 0.3284 - acc: 0.8275 - val_loss: 0.3397 - val_acc: 0.8524\n",
      "Epoch 34/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3289 - acc: 0.8286 - val_loss: 0.3400 - val_acc: 0.8528\n",
      "Epoch 35/35\n",
      "245509/245509 [==============================] - 29s 116us/step - loss: 0.3282 - acc: 0.8284 - val_loss: 0.3398 - val_acc: 0.8525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273b745bc50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.fit(x_train, y_train,\n",
    "          epochs=35,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_cv, y_cv), callbacks=callbacks,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model with small data could not bring test loss lower than 0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save('top_model_full_data_custom_lr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model('top_model_full_data_custom_lr.h5').save_weights('top_model_full_data_custom_lr_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
